# -*- coding: utf-8 -*-
"""
Tools to facilitate running a generirc voting benchmark, which contains an
election model and a parametric assessment of the model.


"""
import os
from textwrap import wrap

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from votesim.utilities.taskmanager import multimap
from votesim.utilities import (lazy_property,
                               clean_lazy_properties,
                               detectfiles)




def benchrun(methods,
             model,
             case_args,
             filename,
             cpus=1,):
    """
    Parameters
    ----------
    methods : list of str
            Voter systems to be assessed by the election model. 
        
    model : func
        Election model running function as 
        
        >>> e = func(**kwargs)
        
        Where 
        
        - `e` is an Election object
        - `kwargs` is a dict of arguments generated by `case_args`
        
    case_args : generator
        Generator that creates the parametric arguments to input into the model.
        Must accept argument `methods` --
        
        >>> generator = case_args(methods)
        >>> args = next(generator)    
            
    filename : str
        Naming prefix for output files
    cpus : int
        Number of processes or CPU's to use
        
    
    Returns
    -------
    e : Election object
        Base election template, can be used to regenerate election specifics
    df : Dataframe
        Results for every election iteration assessed
        
    """
    b = _BenchRunner(model=model, case_args=case_args, filename=filename)
    if cpus > 1:
        return b.runmult(methods, cpus=cpus)
    else:
        return b.run(methods)
    

class _Worker(object):
    """Wrapper for model for multiprocessing"""
    def __init__(self, model):
        self.model = model
        
    def __call__(self, kwargs):
        e = self.model(**kwargs)
        return e.dataframe()
    

class _BenchRunner(object):
    """Run benchmark model and cases.
    
    Parameters
    ----------
    model : func
        Election model running function as 
        
        >>> e = func(*args)
        
        Where 
        
        - `e` is an Election object
        - `*args` are arguments generated by `case_args`
        
    case_args : generator
        Generator that creates the parametric arguments to input into the model.
        Must accept argument `methods` --
        
        >>> generator = case_args(methods)
        >>> args = next(generator)
        
        methods : list of str
            Voter systems to be assessed by the election model. 
    
    """
    def __init__(self, model, case_args, filename='simpleNd-%s.pkl.gz'):
        self.model = model
        self.worker = _Worker(model)
        self.case_args = case_args
        self.filename = filename
        
        
    def run(self, methods):
        iter_args = self.case_args(methods)
        model = self.model
        
        dframes = []
        for itercount, kwargs in enumerate(iter_args):
            print('iteration', itercount, end=', ')
            e = model(**kwargs)
            df = e.dataframe()
            dframes.append(df)
        df = pd.concat(dframes)    
    
        grouped = df.groupby(by='args.election.etype')
        for name, group in grouped:
            
            print('pickling %s' % name)
            fname = self.filename % name
            group.to_pickle(fname)
        print('run done')
        return df, e
    
    
    def runmult(self, methods, cpus=1):
        """Multiprocess benchmark runner"""
        
        # First generate an election
        args1 = next(self.case_args(methods))
        e = self.model(**args1)
        
        # Next do multiprocess iteration
        iter_args = self.case_args(methods)
        worker = self.worker    
        dframes = multimap(worker, iter_args, cpus,)
        df = pd.concat(dframes)    
        
        grouped = df.groupby(by='args.election.etype')
        for name, group in grouped:
            
            print('pickling %s' % name)
            fname = self.filename % name
            group.to_pickle(fname)            
        print('multiprocess run done')
        return df, e



p90 = lambda x : np.percentile(x, 90)
p10 = lambda x : np.percentile(x, 10)
p90.__name__ = 'percentile90'
p10.__name__ = 'percentile10'


class PostProcessor(object):
    """post process benchmark outputs
    
    Parameters
    -----------
    pattern : str
        File name pattern match for module `fnmatch`. Open all dataframe
        files with this pattern in the working directory.
        
        Example -- 'file-*.gz'
        
    dirname : str
        Directory containing dataframe files.
        
    """
    def __init__(self, pattern, dirname=''):
        self.pattern = pattern
        self.dirname = dirname
        self.dataframe = self._read(dirname, pattern)
        self.filter()
        return
    
                
    def _read(self, dirname, pattern):
        if dirname == '':
            dirname = os.getcwd()
        filenames = detectfiles(dirname, pattern)        
        
        # Open up all the benchmark data files
        dframes = []
        for fname in filenames:
            
            dfi = pd.read_pickle(fname,)
            dframes.append(dfi)
                        
        df = pd.concat(dframes)
        df = df.infer_objects()
        return df
    
        
    def relabel(self, oldnames, newnames):
        """Relabel columns"""
        
        renamer = dict(zip(oldnames, newnames))
        df = self.dataframe.rename(columns=renamer)
        self.dataframe = df
        clean_lazy_properties(self)
        return
    
    
    @lazy_property
    def parameters(self):
        """list of str : non-random seed parameters"""
        args = []
        keys = self.dataframe.keys()
        args = [k for k in keys if k.startswith('args.')]
        args = [a for a in args if not a.endswith('.seed')]
        return args
    
    
    @lazy_property
    def etype_parameters(self):
        """Parameters for benchmark name and voting system"""
        arg1 = 'args.election.name'
        arg2 = 'args.election.etype'    
        return [arg1, arg2]
    
    
    @lazy_property
    def user_parameters(self):
        """User parameers include all user defined, etype, and election name"""
        args = self.parameters
        uargs = [a for a in args if a.startswith('args.user.')]
        return  self.etype_parameters + uargs
    
    
    @lazy_property
    def output_keys(self):
        keys = self.dataframe.keys()
        outs = [k for k in keys if k.startswith('output.')]
        return outs
    
    
    def filter(self):
        args = self.user_parameters
        outs = self.output_keys
        columns = args + outs
        self.dataframe = self.dataframe[columns]
        return 
        
    
    def parameter_stats(self, fname):
        """Write mean, 10th percentile, 90th percentile statistics"""
        
        aggfuncs = [
            np.mean,
            p10,
            np.median,
            p90,
            ]
        
        args = self.user_parameters
        gb = self.dataframe.groupby(args)
        
        gm = gb.agg(aggfuncs)
        gm.to_pickle(fname)
        return gm
    
    
    def etype_stats(self, fname):
        """Write overall stats for all runs"""
        
        aggfuncs = [
            np.mean,
            np.std,
            np.min,
            np.max,
            np.median,
            p10,
            p90
            ]
        args = self.etype_parameters
        keys = self.output_keys
        
        df = self.dataframe[args + keys]
        gb = df.groupby(args)
        gm = gb.agg(aggfuncs)
        gm.to_pickle(fname)
        return gm
    
    
    # @lazy_property    
    # def groupby(self):
    #     """Create GroupBy grouped by parameters"""
    #     args = self.user_parameters
    #     return self.dataframe.groupby(args)
    
    
    # @lazy_property
    # def groups_mean(self):
    #     return self.groupby.agg(np.mean)
    
    
    
    # def save_groups_mean(self, fname):
    #     self.groups_mean.to_csv(fname)



# dict of functions available for heatplots    
funcdict = {}
funcdict['subtract100'] = lambda x : (1-x)*100.
funcdict[''] = lambda x : x
funcdict['x100'] = lambda x : x * 100
    

def heatplots(df1, 
              filename,
              x_axis,
              y_axis='etype',
              key='output.regret.efficiency_voter',
              func='',
              stat='mean',
              nrows=1,
              ncols=2,
              vmin=None,
              vmax=None,
              cmap='viridis_r',
              figsize=(12, 7),
              dpi=300,
             ):
    """
    Generate heat plots for benchmarks.
    
    Parameters
    -----------
    df1 : Pandas DataFrame
        Votesim benchmark output DataFrame to read, generated by `PostProcessor`.
    filename : str
        Name pattern of plot files to create, ie "myplot-%s.png"
    x_axis : str
        Name of parameter to set as plot x-axis
    y_axis : str (default 'etype')
        Name of parameter to set as plot y-axis
    key : str
        Name of output parameter to set as plot values.
        Must be a column name of dataframe 
    func : func or str (default '')
        Function to modify key to output plot value `z`; 
        
        >>> z1 = df[key]
        >>> z2 = func(z1)
            
            - `z` is the output value for the plot
            - `df` is the Pandas dataframe
        Str options:
            - '' = Do nothing
            - 'subtract100' : z2 = (1 - z1) * 100
            - 'x100' : z2 = z1 * 100
    stat : str (default 'mean')
        sub-column statistic to retrieve from dataframe. Options are:
        
        - 'mean'
        - 'p10'
        - 'p90'
        - 'median'
        
    nrows, ncols : int (default 1, 2)
        Subplot rows and columns
    figsize : tuple (default (12, 7))
        Size of figure (width, height)        
    """

    if isinstance(func, str):
        func = funcdict[func]
        
    # Retrieve metric to plot
    output_name = key
    output_key = (output_name, stat)
    series = df1[output_key]
    regret = func(series)
    
    # Rename parameter indices
    param_names = regret.index.names    
    param_names_new = []
    for n in param_names:
        new = n.split('.')[-1]
        param_names_new.append(new)
    regret.index.names = param_names_new    
    
    # Retrieve plot axes categories
    param_names2 = list(param_names_new)
    param_names2.remove(x_axis)
    param_names2.remove(y_axis)    
    
    # Sort the tables by the metric
    df3 = regret
    gb3 = df3.groupby(y_axis)
    df3 = gb3.agg('mean')
    isort = np.argsort(df3.values.ravel())
    sort_index = df3.index.values[isort]
    
    # Group by leftoever parameters, build pivot tables with x & y axes.
    groupby = regret.groupby(param_names2)
    groupkeys = list(groupby.groups.keys())
    pivot_tables = []
    for key in groupkeys:
        dfp = groupby.get_group(key)
        dfp = dfp.reset_index()
        dfp = dfp.pivot(y_axis, x_axis, output_key)
        dfp = dfp.loc[sort_index]
        pivot_tables.append(dfp)
        
    # Plot
    figures = []
    for ii, key in enumerate(groupkeys):
        title = ''
        for name, v in zip(param_names2, key):
            s = '%s=%s, ' % (name, v)
            title += s
        # word wrap the title
        title = '\n'.join(wrap(title, 40))
        # subplot controls
        if ii % ncols > 0:
            yticklabels=False
        else:
            yticklabels=True
            f, axes = plt.subplots(nrows=nrows,
                                   ncols=ncols,
                                   figsize=figsize)
            axes = axes.ravel()
            figures.append(f)
            
        ax = axes[ii % ncols]
        dfp = pivot_tables[ii]
        sns.heatmap(dfp, 
                    ax=ax,
                    annot=True, 
                    fmt=".1f", 
                    cbar=False,
                    linewidths=.5,
                    yticklabels=yticklabels,
                    vmin=vmin,
                    vmax=vmax, 
                    cmap=cmap,
                    )        
        ax.set_title(title)
        ax.set_ylabel('')
        
    
    for ii, f in enumerate(figures):
        f.savefig(filename % ii, dpi=dpi)

    return figures        





