# -*- coding: utf-8 -*-
"""
Tools to facilitate running a generirc voting benchmark, which contains an
election model and a parametric assessment of the model.


"""
import os
from textwrap import wrap
import itertools
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from votesim.utilities.taskmanager import multimap
from votesim.utilities import (lazy_property,
                               clean_lazy_properties,
                               detectfiles)




def benchrun(methods,
             model,
             case_args,
             filename,
             cpus=1,):
    """
    Parameters
    ----------
    methods : list of str
            Voter systems to be assessed by the election model. 
        
    model : func
        Election model running function as 
        
        >>> e = func(**kwargs)
        
        Where 
        
        - `e` is an Election object
        - `kwargs` is a dict of arguments generated by `case_args`
        
    case_args : generator
        Generator that creates the parametric arguments to input into the model.
        Must accept argument `methods` --
        
        >>> generator = case_args(methods)
        >>> args = next(generator)    
            
    filename : str
        Naming prefix for output files
    cpus : int
        Number of processes or CPU's to use
        
    
    Returns
    -------
    e : Election object
        Base election template, can be used to regenerate election specifics
    df : Dataframe
        Results for every election iteration assessed
        
    """
    b = _BenchRunner(model=model, case_args=case_args, filename=filename)
    if cpus > 1:
        return b.runmult(methods, cpus=cpus)
    else:
        return b.run(methods)
    

class _Worker(object):
    """Wrapper for model for multiprocessing
    
    Atttributes
    -------------
    election : Election
        last election object generated by worker
    """
    def __init__(self, model):
        self.model = model
        
    def __call__(self, kwargs):
        e = self.model(**kwargs)
        self.election  = e
        return e.dataframe()
    

class _BenchRunner(object):
    """Run benchmark model and cases with multiprocessing support
    
    Parameters
    ----------
    model : func
        Election model running function as 
        
        >>> e = func(*args)
        
        Where 
        
        - `e` is an Election object
        - `*args` are arguments generated by `case_args`
        
    case_args : generator
        Generator that creates the parametric arguments to input into the model.
        Must accept argument `methods` --
        
        >>> generator = case_args(methods)
        >>> args = next(generator)
        
        methods : list of str
            Voter systems to be assessed by the election model. 
    
    """
    def __init__(self, model, case_args, filename='simpleNd-%s.pkl.gz'):
        self.model = model
        self.worker = _Worker(model)
        self.case_args = case_args
        self.filename = filename
        
        
    def run(self, methods):
        iter_args = self.case_args(methods)
        model = self.model
        
        dframes = []
        for itercount, kwargs in enumerate(iter_args):
            print('iteration', itercount, end=', ')
            e = model(**kwargs)
            df = e.dataframe()
            dframes.append(df)
        df = pd.concat(dframes)    
    
        grouped = df.groupby(by='args.etype')
        for name, group in grouped:
            
            print('pickling %s' % name)
            fname = self.filename % name
            group.to_pickle(fname)
        print('run done')
        return df, e
    
    
    def runmult(self, methods, cpus=1):
        """Multiprocess benchmark runner"""
        
        # Multiprocess iteration
        iter_args = self.case_args(methods)
        worker = self.worker    
        dframes = multimap(worker, iter_args, cpus,)
        df = pd.concat(dframes)    
        
        grouped = df.groupby(by='args.etype')
        for name, group in grouped:
            
            print('pickling %s' % name)
            fname = self.filename % name
            group.to_pickle(fname)            
        print('multiprocess run done')
        #e = worker.election
        return df #, e



p90 = lambda x : np.percentile(x, 90)
p10 = lambda x : np.percentile(x, 10)
p90.__name__ = 'percentile90'
p10.__name__ = 'percentile10'


class Reader(object):
    """Read benchmark outputs
    
    Parameters
    -----------
    pattern : str
        File name pattern match for module `fnmatch`. Open all dataframe
        files with this pattern in the working directory.
        
        Example -- 'file-*.gz'
        
    dirname : str
        Directory containing dataframe files.
        
    """
    def __init__(self, pattern=None, dirname='', df=None):
        self.pattern = pattern
        self.dirname = dirname
        if df is not None:
            self.dataframe = df
        else:
            self.dataframe = self._read(dirname, pattern)
        return
    
                
    def _read(self, dirname, pattern) -> pd.DataFrame:
        if dirname == '':
            dirname = os.getcwd()
        filenames = detectfiles(dirname, pattern)        
        
        # Open up all the benchmark data files
        dframes = []
        for fname in filenames:
            
            dfi = pd.read_pickle(fname,)
            dframes.append(dfi)
                        
        df = pd.concat(dframes)
        df = df.infer_objects()
        df = df.reset_index(drop=True)
        return df  
    
    
    @lazy_property
    def parameters(self):
        """list of str : non-random seed parameters"""
        args = []
        keys = self.dataframe.keys()
        args = [k for k in keys if k.startswith('args.')]
        args = [a for a in args if not a.endswith('.seed')]
        return args
    
    
    @lazy_property
    def parameters_etype(self):
        """list of str : Parameters for benchmark name and voting system"""
        arg1 = 'args.name'
        arg2 = 'args.etype'    
        return [arg1, arg2]
    
    
    @lazy_property
    def parameters_user(self):
        """list of str : User parameters include all user defined, etype,
        and election name"""
        args = self.parameters
        uargs = [a for a in args if a.startswith('args.user.')]
        return  self.parameters_etype + uargs
    
    
    @lazy_property
    def output_keys(self):
        keys = self.dataframe.keys()
        outs = [k for k in keys if k.startswith('output.')]
        return outs
    
    
    def _filtered(self):
        args = self.parameters_user
        outs = self.output_keys
        columns = args + outs
        return self.dataframe[columns]
    
    
    @lazy_property
    def post_data(self):
        """
        Retrieve filtered output Pandas DataFrame 
        """
        return self._filtered()
    
    
    


class __PostProcessor(object):
    """post process benchmark outputs
    
    Parameters
    -----------
    pattern : str
        File name pattern match for module `fnmatch`. Open all dataframe
        files with this pattern in the working directory.
        
        Example -- 'file-*.gz'
        
    dirname : str
        Directory containing dataframe files.
        
    """
    def __init__(self, pattern=None, dirname='', df=None):
        self.pattern = pattern
        self.dirname = dirname
        if df is not None:
            self.dataframe = df
        else:
            self.dataframe = self._read(dirname, pattern)
        self.filter()
        return
    
                
    def _read(self, dirname, pattern):
        if dirname == '':
            dirname = os.getcwd()
        filenames = detectfiles(dirname, pattern)        
        
        # Open up all the benchmark data files
        dframes = []
        for fname in filenames:
            
            dfi = pd.read_pickle(fname,)
            dframes.append(dfi)
                        
        df = pd.concat(dframes)
        df = df.infer_objects()
        df = df.reset_index()
        return df
    
    
    
    
    
        
    def relabel(self, oldnames, newnames):
        """Relabel columns"""
        
        renamer = dict(zip(oldnames, newnames))
        df = self.dataframe.rename(columns=renamer)
        self.dataframe = df
        clean_lazy_properties(self)
        return
    
    
    @lazy_property
    def parameters(self):
        """list of str : non-random seed parameters"""
        args = []
        keys = self.dataframe.keys()
        args = [k for k in keys if k.startswith('args.')]
        args = [a for a in args if not a.endswith('.seed')]
        return args
    
    
    @lazy_property
    def etype_parameters(self):
        """Parameters for benchmark name and voting system"""
        arg1 = 'args.name'
        arg2 = 'args.etype'    
        return [arg1, arg2]
    
    
    @lazy_property
    def user_parameters(self):
        """User parameers include all user defined, etype, and election name"""
        args = self.parameters
        uargs = [a for a in args if a.startswith('args.user.')]
        return  self.etype_parameters + uargs
    
    
    @lazy_property
    def output_keys(self):
        keys = self.dataframe.keys()
        outs = [k for k in keys if k.startswith('output.')]
        return outs
    
    
    def filter(self):
        args = self.user_parameters
        outs = self.output_keys
        columns = args + outs
        self.dataframe = self.dataframe[columns]
        return 
        
    
    # def parameter_stats(self, fname=None):
    #     """Write mean, 10th percentile, 90th percentile statistics"""
        
    #     aggfuncs = [
    #         np.mean,
    #         p10,
    #         np.median,
    #         p90,
    #         ]
        
    #     args = self.user_parameters
    #     gb = self.dataframe.groupby(args)
        
    #     gm = gb.agg(aggfuncs)
    #     if fname is not None:
    #         gm.to_pickle(fname)
    #     return gm
    
    
    # def etype_stats(self, fname):
    #     """Write overall stats for all runs"""
        
    #     aggfuncs = [
    #         np.mean,
    #         np.std,
    #         np.min,
    #         np.max,
    #         np.median,
    #         p10,
    #         p90
    #         ]
    #     args = self.etype_parameters
    #     keys = self.output_keys
        
    #     df = self.dataframe[args + keys]
    #     gb = df.groupby(args)
    #     gm = gb.agg(aggfuncs)
    #     gm.to_pickle(fname)
    #     return gm



class CaseGenerator(object):
    """Generate arguments for input into model. Call the object to generate. 

    Parameters
    ----------
    **kwargs : dict
        dict of parameters. If the value is iterable, it will be
        iterated upon using `itertools.product`        
    """
    
    def __init__(self, **kwargs):
        
        for k, v in kwargs.items():
            is_iter = True
            
            if isinstance(v, str):
                is_iter = False
            try:
                iter(v)
            except TypeError:
                is_iter = False
            
            if not is_iter:
                kwargs[k] = [v]
                
        self.kwargs = kwargs
        
        # iters = itertools.product(*self.kwargs.values())
        # self._iters = iters
        self._keys = kwargs.keys()
        return            
    
    
    def __call__(self, methods):
        """Build a iterator that generates arguments for the benchmark model
        
        Parameters
        -----------
        methods : list of str
            Election method names you wish to run.
            
        Yields
        ------
        out : dict
            Keyword arguments and argument values
            
        """
        iters =  itertools.product(*self.kwargs.values())
        for xargs in iters:
            d = dict(zip(self._keys, xargs))
            d['methods'] = methods
            yield d



# class CaseGenerator(object):
#     def __init__(self, kwargs):
#         for k, v in kwargs.items():
#             is_iter = True
            
#             if isinstance(v, str):
#                 is_iter = False
#             try:
#                 iter(v)
#             except TypeError:
#                 is_iter = False
            
#             if not is_iter:
#                 kwargs[k] = [v]    
#         self.kwargs = kwargs
#         return
    
#     def _build_generator(self):
#         iters = itertools.produ
    


class CreateBenchmark(object):
    """Base object for creating a benchmark
    
    Parameters
    -----------
    name : str
        Election benchmark name
    model : func
        Election model function where
        
        >>> election = func(**kwargs)
        
    case_args : generator
        Argument generator in which produces
        
        >>>  kwargs = next(generator(methods))
        
        Where methods is a list of election methods, e.g. ['plurality', 'irv']
    
    Returns
    -------
    df : DataFrame
        Output data
    """
    def __init__(self, name, model, case_args):
        self.name = name
        self.model = model
        self.case_args = case_args
        
        self.output_file = name + '-run-%s.pkl.gz'
        self.output_pattern = self.output_file.replace('%s', '*')
        
        #self.post_file = name + '-post-categories.pkl.gz'        
        #self.plot_file = name + '-plot-category-%d.png'        
        self.dirname = ''
        
        #self._case_args = CaseGenerator(**kwargs)
        return
    
    
    # @property
    # def default_model(self):
    #     """You can define a default voter model here when inheriting"""
    #     raise AttributeError('Default model has not yet been defined')
    #     return
    
    
    # @property
    # def default_name(self):
    #     raise AttributeError('Default name has not yet been defined')
        
        
    # @property
    # def default_case_args(self):
    #     raise AttributeError('Default case arguments not yet defined')
    
    
    def run(self, methods, cpus=1, filename='', dirname=''):
        """Run benchmark"""
        if filename == '':
            filename = self.output_file
        
        if dirname != '':
            filename = os.path.join(dirname, filename)
            self.dirname = dirname
            
        return benchrun(methods,
                        model=self.model, 
                        case_args = self.case_args,
                        cpus=cpus, 
                        filename=filename)    
   
    
    def read(self, pattern='', dirname=''):
        """Read benchmark output"""
        if dirname != '':
            self.dirname = dirname
            
        if pattern == '':
            pattern = self.output_pattern
            
        p = Reader(pattern, self.dirname)
        self._reader = p
        return p        
    
    
    def rerun(self, series=None, index=None, df=None):
        """Rerun a specific election using output data
        
        Parameters
        -----------
        series : Pandas Series
            Election output data
        index : int
            Index location of election output data
        df : Pandas DataFrame
            Dataframe of election output if available. 
        
        Returns
        --------
        out : Election
            Election object.
        """
        e = self.model(name='rerun', methods=['plurality'])
        if index is not None:
            if df is None:
                df = self._reader.dataframe
            series = df.loc[index]            
        return e.rerun(series)
    
    @property
    def reader(self):
        return self._reader


# dict of functions available for heatplots    
funcdict = {}
funcdict['subtract100'] = lambda x : (1-x)*100.
funcdict[''] = lambda x : x
funcdict['x100'] = lambda x : x * 100
    

def __heatplots(df1, 
              filename,
              x_axis,
              y_axis='etype',
              key='output.regret.efficiency_voter',
              func='',
              stat='mean',
              nrows=1,
              ncols=2,
              vmin=None,
              vmax=None,
              cmap='viridis_r',
              figsize=(12, 7),
              dpi=300,
             ):
    """
    Generate heat plots for benchmarks.
    
    Parameters
    -----------
    df1 : Pandas DataFrame
        Votesim benchmark output DataFrame to read, generated by `PostProcessor`.
    filename : str
        Name pattern of plot files to create, ie "myplot-%s.png"
    x_axis : str
        Name of parameter to set as plot x-axis
    y_axis : str (default 'etype')
        Name of parameter to set as plot y-axis
    key : str
        Name of output parameter to set as plot values.
        Must be a column name of dataframe 
    func : func or str (default '')
        Function to modify key to output plot value `z`; 
        
        >>> z1 = df[key]
        >>> z2 = func(z1)
            
            - `z` is the output value for the plot
            - `df` is the Pandas dataframe
        Str options:
            - '' = Do nothing
            - 'subtract100' : z2 = (1 - z1) * 100
            - 'x100' : z2 = z1 * 100
    stat : str (default 'mean')
        sub-column statistic to retrieve from dataframe. Options are:
        
        - 'mean'
        - 'p10'
        - 'p90'
        - 'median'
        
    nrows, ncols : int (default 1, 2)
        Subplot rows and columns
    figsize : tuple (default (12, 7))
        Size of figure (width, height)        
    """

    if isinstance(func, str):
        func = funcdict[func]
        
    # Retrieve metric to plot
    output_name = key
    output_key = (output_name, stat)
    series = df1[output_key]
    regret = func(series)
    
    # Rename parameter indices
    param_names = regret.index.names    
    param_names_new = []
    for n in param_names:
        new = n.split('.')[-1]
        param_names_new.append(new)
    regret.index.names = param_names_new    
    
    # Retrieve plot axes categories
    param_names2 = list(param_names_new)
    param_names2.remove(x_axis)
    param_names2.remove(y_axis)    
    
    # Sort the tables by the metric
    df3 = regret
    gb3 = df3.groupby(y_axis)
    df3 = gb3.agg('mean')
    isort = np.argsort(df3.values.ravel())
    sort_index = df3.index.values[isort]
    
    # Group by leftoever parameters, build pivot tables with x & y axes.
    groupby = regret.groupby(param_names2)
    groupkeys = list(groupby.groups.keys())
    pivot_tables = []
    for key in groupkeys:
        dfp = groupby.get_group(key)
        dfp = dfp.reset_index()
        dfp = dfp.pivot(y_axis, x_axis, output_key)
        dfp = dfp.loc[sort_index]
        pivot_tables.append(dfp)
        
    # Plot
    figures = []
    for ii, key in enumerate(groupkeys):
        title = ''
        for name, v in zip(param_names2, key):
            s = '%s=%s, ' % (name, v)
            title += s
        # word wrap the title
        title = '\n'.join(wrap(title, 40))
        # subplot controls
        if ii % ncols > 0:
            yticklabels=False
        else:
            yticklabels=True
            f, axes = plt.subplots(nrows=nrows,
                                   ncols=ncols,
                                   figsize=figsize)
            try:
                axes = axes.ravel()
            except AttributeError:
                pass
            figures.append(f)
            
        try:
            ax = axes[ii % ncols]
        except TypeError:
            ax = axes
        
        dfp = pivot_tables[ii]
        sns.heatmap(dfp, 
                    ax=ax,
                    annot=True, 
                    fmt=".1f", 
                    cbar=False,
                    linewidths=.5,
                    yticklabels=yticklabels,
                    vmin=vmin,
                    vmax=vmax, 
                    cmap=cmap,
                    )        
        ax.set_title(title)
        ax.set_ylabel('')
        
    
    for ii, f in enumerate(figures):
        f.savefig(filename % ii, dpi=dpi)

    return figures        





